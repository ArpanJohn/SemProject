{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from Tools import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([[1,2,3],[4,5,6]])\n",
    "# b = nn.Flatten(a)\n",
    "# print(a.shape)\n",
    "# print(b)\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\21.01-5_DISTPAR\n",
      "['bn100417393_DISTPAR', 'bn110702686_DISTPAR', 'bn151229987_DISTPAR', 'bn160308812_DISTPAR', 'bn230212974_DISTPAR']\n",
      "['bn100417393_DISTPAR', 'bn110702686_DISTPAR', 'bn151229987_DISTPAR', 'bn160308812_DISTPAR', 'bn230212974_DISTPAR']\n",
      "bn100417393_DISTPAR\n",
      "bn110702686_DISTPAR\n",
      "bn151229987_DISTPAR\n",
      "bn160308812_DISTPAR\n",
      "bn230212974_DISTPAR\n",
      "C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\21.01-5_GRB\n",
      "['bn090516137_GRB', 'bn130320560_GRB', 'bn190906767_GRB', 'bn210501205_GRB', 'bn231224868_GRB']\n",
      "['bn090516137_GRB', 'bn130320560_GRB', 'bn190906767_GRB', 'bn210501205_GRB', 'bn231224868_GRB']\n",
      "bn090516137_GRB\n",
      "bn130320560_GRB\n",
      "bn190906767_GRB\n",
      "bn210501205_GRB\n",
      "bn231224868_GRB\n",
      "C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\21.01-5_SGR\n",
      "['bn160727543_SGR', 'bn220626269_SGR', 'bn220709626_SGR', 'bn221109533_SGR', 'bn221204313_SGR']\n",
      "['bn160727543_SGR', 'bn220626269_SGR', 'bn220709626_SGR', 'bn221109533_SGR', 'bn221204313_SGR']\n",
      "bn160727543_SGR\n",
      "bn220626269_SGR\n",
      "bn220709626_SGR\n",
      "bn221109533_SGR\n",
      "bn221204313_SGR\n",
      "C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\21.01-5_TGF\n",
      "['bn100911473_TGF', 'bn140630748_TGF', 'bn140912846_TGF', 'bn170909434_TGF', 'bn190105022_TGF']\n",
      "['bn100911473_TGF', 'bn140630748_TGF', 'bn140912846_TGF', 'bn170909434_TGF', 'bn190105022_TGF']\n",
      "bn100911473_TGF\n",
      "bn140630748_TGF\n",
      "bn140912846_TGF\n",
      "bn170909434_TGF\n",
      "bn190105022_TGF\n",
      "(20, 7, 199)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arpan\\AppData\\Local\\Temp\\ipykernel_11892\\256621757.py:15: DeprecationWarning: loadtxt(): Parsing an integer via a float is deprecated.  To avoid this warning, you can:\n",
      "    * make sure the original data is stored as integers.\n",
      "    * use the `converters=` keyword argument.  If you only use\n",
      "      NumPy 1.23 or later, `converters=float` will normally work.\n",
      "    * Use `np.loadtxt(...).astype(np.int64)` parsing the file as\n",
      "      floating point and then convert it.  (On all NumPy versions.)\n",
      "  (Deprecated NumPy 1.23)\n",
      "  loaded_data = np.loadtxt(os.path.join(dir_path,i,file), dtype=np.int16, delimiter='\\t').astype(np.int16)\n"
     ]
    }
   ],
   "source": [
    "# importing data\n",
    "# Read the 2D array back from the text file\n",
    "dir_path = tools.json_path(r'data_path.json')\n",
    "event_types = {1:'GRB',2:'TGF',3:'SGR',4:'SFLARE',5:'DISTPAR'}\n",
    "data_list = ['21.01-5_DISTPAR','21.01-5_GRB','21.01-5_SGR','21.01-5_TGF']\n",
    "X = []\n",
    "Y = []\n",
    "for i in data_list:\n",
    "    print(os.path.join(dir_path,i))\n",
    "    file_list = [f for f in os.listdir(os.path.join(dir_path,i))]\n",
    "    print(file_list)\n",
    "    print(os.listdir(os.path.join(dir_path,i)))\n",
    "    for file in file_list:\n",
    "        print(file)\n",
    "        loaded_data = np.loadtxt(os.path.join(dir_path,i,file), dtype=np.int16, delimiter='\\t').astype(np.int16)\n",
    "        X.append(loaded_data)\n",
    "        for key,value in event_types.items():\n",
    "            if value in file:\n",
    "                Y.append(key)\n",
    "                break\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "print(X.shape)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arpan\\AppData\\Local\\Temp\\ipykernel_5088\\2613356650.py:22: DeprecationWarning: loadtxt(): Parsing an integer via a float is deprecated.  To avoid this warning, you can:\n",
      "    * make sure the original data is stored as integers.\n",
      "    * use the `converters=` keyword argument.  If you only use\n",
      "      NumPy 1.23 or later, `converters=float` will normally work.\n",
      "    * Use `np.loadtxt(...).astype(np.int64)` parsing the file as\n",
      "      floating point and then convert it.  (On all NumPy versions.)\n",
      "  (Deprecated NumPy 1.23)\n",
      "  loaded_data = np.loadtxt(file, dtype=np.int16, delimiter='\\t').astype(np.int16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 7, 50000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from Tools import tools\n",
    "\n",
    "# importing data\n",
    "# Read the 2D array back from the text file\n",
    "dir_path = r\"C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\data_set_1_proccessed\"\n",
    "event_types = {1:'GRB',2:'TGF',3:'SGR',4:'SFLARE',5:'DISTPAR'}\n",
    "\n",
    "# Replace 'your_search_string' with the string you are looking for in file names\n",
    "search_string = 'bn'\n",
    "search_pattern = os.path.join(dir_path, f'*{search_string}*')\n",
    "matching_files = glob.glob(search_pattern)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for file in matching_files:\n",
    "    event_type , event_name = file.split('\\\\')[-1].split('_')\n",
    "    loaded_data = np.loadtxt(file, dtype=np.int16, delimiter='\\t').astype(np.int16)\n",
    "    X.append(loaded_data)\n",
    "    for key,value in event_types.items():\n",
    "        if value in file:\n",
    "            Y.append(key)\n",
    "            break\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the array in bytes: 80500000 bytes\n"
     ]
    }
   ],
   "source": [
    "# Find the space taken by the array in bytes\n",
    "array_size_bytes = X.nbytes \n",
    "\n",
    "print(f\"Size of the array in bytes: {array_size_bytes} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 7, 50000)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.reshape(20, 7 * 199)\n",
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (103, 7, 50000)\n",
      "X_test shape (12, 7, 50000)\n",
      "Y_train shape (103,)\n",
      "Y_test shape (12,)\n"
     ]
    }
   ],
   "source": [
    "# Split the train and the validation set for the fitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train = (X)\n",
    "Y_train = (Y)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)\n",
    "print(\"X_train shape\",X_train.shape)\n",
    "print(\"X_test shape\",X_val.shape)\n",
    "print(\"Y_train shape\",Y_train.shape)\n",
    "print(\"Y_test shape\",Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\arpan\\miniconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\arpan\\miniconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\arpan\\miniconda3\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\arpan\\miniconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\arpan\\miniconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arpan\\miniconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\arpan\\miniconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "2/2 [==============================] - 39s 11s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 38s 10s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 38s 11s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 43s 11s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 39s 13s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "4/4 [==============================] - 4s 837ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Build the CNN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (1, 3), activation='relu', input_shape=(X_train.shape[1:])+tuple([1])))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (1, 1), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_train, Y_train)\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 1s - loss: 0.0000e+00 - accuracy: 1.0000 - 503ms/epoch - 503ms/step\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_val, Y_val, verbose=2)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
